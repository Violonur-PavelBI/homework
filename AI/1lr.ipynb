{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Mapping\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn as skl\n",
    "from sklearn import datasets\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython import display\n",
    "from numpy.random import permutation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_sample(xs, ys):\n",
    "    \"\"\"\n",
    "        stochastic_sample: sample with replacement one x and one y\n",
    "        xs: all point on the plane\n",
    "        ys: all response on the plane\n",
    "        \n",
    "        return the one randomly selected x and y point\n",
    "    \"\"\"\n",
    "    perm = permutation(len(xs))\n",
    "    x = xs[perm[0]]\n",
    "    y = ys[perm[0]]\n",
    "    return x, y\n",
    "\n",
    "class lenDataloader():\n",
    "    '''бесмысленый класс для создания случайного бача из пар точек x,y созданный пока я забыл что эти точки и есть оптимизационные параметры'''\n",
    "    # инициатия двухмерного датасета\n",
    "    def __init__(self,x,y,batch_size: int = 1,shuffle: bool = True,drop_last: bool = False) -> None:\n",
    "        self.X=x\n",
    "        self.Y=y\n",
    "        self.batch_size=batch_size\n",
    "        self.drop_last=drop_last\n",
    "        self.shuffle=shuffle\n",
    "        self.batchindex=0\n",
    "        self.endbatchindex=0\n",
    "        self.X1=[]\n",
    "        self.Y1=[]\n",
    "    # отображение длины датасеета \n",
    "    def len(self) -> int:\n",
    "        return len(self.X)\n",
    "    # перемешивания индексов датасета если включено перемешивание иначе копируем\n",
    "    def permutation(self):\n",
    "        if (self.shuffle==True):\n",
    "            perm = permutation(self.len)\n",
    "            self.X1=[self.X[ind] for ind in perm]\n",
    "            self.Y1=[self.Y[ind] for ind in perm]\n",
    "        else:\n",
    "            self.X1=self.X\n",
    "            self.Y1=self.Y\n",
    "    def ReturnPermDataset(self,indxstart:int,indxstop=None,indxstep=1):\n",
    "        if indxstop==None:\n",
    "            return self.X1[indxstart],self.Y1[indxstart]\n",
    "        else:\n",
    "            return [self.X1[indxstart:indxstop:indxstep],self.Y1[indxstart:indxstop:indxstep]]\n",
    "    \n",
    "    def returnBatchSet(self):\n",
    "        if (self.batchindex==0):\n",
    "            # инициализация доп сета для перемешивания \n",
    "            self.permutation()\n",
    "            self.endbatchindex=(self.len() // self.batch_size)-1\n",
    "            # если датасет не делиться на ровные батчи отбрасываем последний по флагу\n",
    "            if ((self.drop_last==True) and (self.len() % self.batch_size !=0)):\n",
    "                self.endbatchindex-=1\n",
    "        \n",
    "        if ((self.drop_last==False) and (self.len() % self.batch_size !=0)and (self.batchindex+1==self.endbatchindex)):\n",
    "            batch[self.ReturnPermDataset(self.batchindex*self.batch_size, self.len())]\n",
    "        else:\n",
    "            batch=[self.ReturnPermDataset(self.batchindex*self.batch_size, self.batchindex*self.batch_size+self.batch_size)]\n",
    "        self.batchindex+=1\n",
    "        \n",
    "        return batch[0],batch[1]\n",
    "    def endEpoch(self):\n",
    "        self.batchindex=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, array([-24,  40]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#функция 1\n",
    "def Himmelblau(x: np.float32, y: np.float32) -> np.float64:\n",
    "    '''\n",
    "    Функция Химмельблау\n",
    "    \n",
    "    Args:\n",
    "        x(np.ndarray): Аргумент 1\n",
    "        y(np.ndarray): Аргумент 2\n",
    "        \n",
    "    Returns:\n",
    "        np.float64: Результат функции\n",
    "    '''\n",
    "    return (np.square(np.square(x)+y-11)+np.square(x+np.square(y)-7));\n",
    "\n",
    "#градиент 1\n",
    "def Himmelblau_Grad(x: np.ndarray, y: np.ndarray) -> np.float64:\n",
    "    return np.array([(4*x*(np.square(x)+y-11)+2*(x+np.square(y)-7)), (2*(np.square(x)+y-11)+4*y*(x+np.square(y)-7))]);\n",
    "\n",
    "Himmelblau(2, 3), Himmelblau_Grad(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#набор точек\n",
    "x, y = skl.datasets.make_blobs(n_samples=2, centers=None, n_features=1, random_state=0)\n",
    "y=np.reshape(y,x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbol import yield_stmt\n",
    "\n",
    "\n",
    "def mu_func(x: np.float32, y: np.float32) -> np.float64:\n",
    "    '''\n",
    "    Функция Химмельблау\n",
    "    \n",
    "    Args:\n",
    "        x(np.ndarray): Аргумент 1\n",
    "        y(np.ndarray): Аргумент 2\n",
    "        \n",
    "    Returns:\n",
    "        np.float64: Результат функции\n",
    "    '''\n",
    "    return x**2+y**2;\n",
    "\n",
    "#градиент 1\n",
    "def mu_func_Grad(x: np.ndarray, y: np.ndarray) -> np.float64:\n",
    "    return np.array([2*x, 2*y]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([1.0,2.,3.,4.,1.])\n",
    "b=np.array([1.,2.,3.,4.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4., 6., 8., 2.],\n",
       "       [2., 4., 6., 8., 2.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_func_Grad(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.9998581 , 2.99988328, 2.9999038 , 3.00003285, 2.9998581 ]),\n",
       " array([2.00034244, 2.00028171, 2.00023218, 1.9999207 , 2.00034244]),\n",
       " array([1.76693815e-06, 1.19572409e-06, 8.12212956e-07, 9.47322856e-08,\n",
       "        1.76693815e-06]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_GD_LRS_nest(Himmelblau,Himmelblau_Grad,a,b,lr=0.1,lre=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GDF\n",
    "def my_GD(f: Mapping, df: Mapping, x: np.ndarray, y: np.ndarray, lr: float = 0.01,\n",
    "          Epoch: int = 100) -> Tuple [np.ndarray, np.ndarray, np.float32]:\n",
    "    '''Моя простейшая реализация градиентного спуска.\n",
    "    \n",
    "    Args:\n",
    "        f (Mapping): Функционал для оптимизации\n",
    "        df (Mapping): Градиент оптимизирующего функционала\n",
    "        x0 (np.ndarray): Стартовая точка 1\n",
    "        y0 (np.ndarray): Стартовая точка 2\n",
    "        lr (float): Скорость обучения. Default=0,01.\n",
    "        T (int): Количество итераций.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple [np.ndarray, np.float32]: (x_optimal, f(x_optimal)).\n",
    "    \n",
    "    '''\n",
    "\n",
    "    for i in range(Epoch):\n",
    "        print(x,y)\n",
    "        n=df(x, y)\n",
    "        print(n)\n",
    "        x = x - lr*n[0]\n",
    "        y = y - lr*n[1]\n",
    "        \n",
    "    return x, y, f(x, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 3., 3., 3.]),\n",
       " array([2., 2., 2., 2.]),\n",
       " array([2.23017289e-24, 2.23017289e-24, 2.23017289e-24, 2.23017289e-24]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_GD(Himmelblau,Himmelblau_Grad,[0],[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GD_LRS(f: Mapping, df: Mapping, x: np.ndarray, y: np.ndarray, lr: float = 0.01,\n",
    "          Epoch: int = 100, lre: int = 7, g: float = 0.1) -> Tuple [np.ndarray, np.ndarray, np.float32]:\n",
    "    '''\n",
    "    Моя простейшая реализация градиентного спуска + Learning Rate Schedule.\n",
    "    \n",
    "    Args:\n",
    "        f (Mapping): Функционал для оптимизации\n",
    "        df (Mapping): Градиент оптимизирующего функционала\n",
    "        x0 (np.ndarray): Стартовая точка 1\n",
    "        y0 (np.ndarray): Стартовая точка 2\n",
    "        lr (float): Скорость обучения. Default=0,01.\n",
    "        T (int): Количество итераций.\n",
    "        lre (int): Через сколько эпох мы уменьшим lr. Default = 7.\n",
    "        g (float): Коэфициент уменьшения lr [0,1). Default = 0.1\n",
    "    \n",
    "    Returns:\n",
    "        Tuple [np.ndarray, np.float32]: (x_optimal, f(x_optimal)).\n",
    "    \n",
    "    '''\n",
    "\n",
    "    for i in range(Epoch):\n",
    "        if ((i%lre)==0):\n",
    "            lr *= g\n",
    "        n=df(x, y)\n",
    "        x = x - lr*n[0]\n",
    "        y = y - lr*n[1]\n",
    "        \n",
    "    return x, y, f(x, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.06332714],\n",
       "        [ 5.86606369]]),\n",
       " array([[-0.13452826],\n",
       "        [ 0.86547174]]),\n",
       " array([[-164.80300229],\n",
       "        [-589.48081385]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_GD_LRS(Himmelblau,Himmelblau_Grad,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GD_LRS_mom(f: Mapping, df: Mapping, x: np.ndarray, y: np.ndarray, lr: float = 0.01,\n",
    "          Epoch: int = 100, lre: int = 7, g: float = 0.1, momentum: float = 0.1) -> Tuple [np.ndarray, np.ndarray, np.float32]:\n",
    "    '''\n",
    "    Моя простейшая реализация градиентного спуска + Learning Rate Schedule.\n",
    "    \n",
    "    Args:\n",
    "        f (Mapping): Функционал для оптимизации\n",
    "        df (Mapping): Градиент оптимизирующего функционала\n",
    "        x0 (np.ndarray): Стартовая точка 1\n",
    "        y0 (np.ndarray): Стартовая точка 2\n",
    "        lr (float): Скорость обучения. Default=0,01.\n",
    "        T (int): Количество итераций.\n",
    "        lre (int): Через сколько эпох мы уменьшим lr. Default = 7.\n",
    "        g (float): Коэфициент уменьшения lr [0,1). Default = 0.1\n",
    "    \n",
    "    Returns:\n",
    "        Tuple [np.ndarray, np.float32]: (x_optimal, f(x_optimal)).\n",
    "    \n",
    "    '''\n",
    "    n=np.zeros(df(x, y).shape)\n",
    "    for i in range(Epoch):\n",
    "        if ((i%lre)==0):\n",
    "            lr *= g\n",
    "        n=momentum*n-lr*df(x, y)\n",
    "        x = x + n[0]\n",
    "        y = y + n[1]\n",
    "    return x, y, f(x, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GD_LRS_nest(f: Mapping, df: Mapping, x0: np.ndarray, y0: np.ndarray, lr: float = 0.01,\n",
    "          Epoch: int = 100, lre: int = 7, g: float = 0.1, momentum: float = 0.1) -> Tuple [np.ndarray, np.ndarray, np.float32]:\n",
    "    '''\n",
    "    Моя простейшая реализация градиентного спуска + Learning Rate Schedule.\n",
    "    \n",
    "    Args:\n",
    "        f (Mapping): Функционал для оптимизации\n",
    "        df (Mapping): Градиент оптимизирующего функционала\n",
    "        x0 (np.ndarray): Стартовая точка 1\n",
    "        y0 (np.ndarray): Стартовая точка 2\n",
    "        lr (float): Скорость обучения. Default=0,01.\n",
    "        T (int): Количество итераций.\n",
    "        lre (int): Через сколько эпох мы уменьшим lr. Default = 7.\n",
    "        g (float): Коэфициент уменьшения lr [0,1). Default = 0.1\n",
    "    \n",
    "    Returns:\n",
    "        Tuple [np.ndarray, np.float32]: (x_optimal, f(x_optimal)).\n",
    "    \n",
    "    '''\n",
    "    x = x0;\n",
    "    y = y0;\n",
    "    n=np.zeros(df(x, y).shape)\n",
    "    for i in range(Epoch):\n",
    "        if ((i%lre)==0):\n",
    "            lr *= g\n",
    "        n=momentum*n-lr*df(x+momentum*n[0], y+momentum*n[1])\n",
    "        x = x + n[0]\n",
    "        y = y + n[1]\n",
    "        \n",
    "    return x, y, f(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.29205812]), 0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_sample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.06332714],\n",
       "        [ 5.86606369]]),\n",
       " array([[-0.13452826],\n",
       "        [ 0.86547174]]),\n",
       " array([[-164.80300229],\n",
       "        [-589.48081385]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#тест GD 1\n",
    "my_GD_LRS(Himmelblau, Himmelblau_Grad, x, y)\n",
    "#тест GD+LRS 1\n",
    "# xlr,ylr,zlr=my_GD_LRS(Himmelblau, Himmelblau_Grad, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция 1\n",
    "def McCormick(x: np.float32, y: np.float32) -> np.float64:\n",
    "    '''\n",
    "    Функция Химмельблау\n",
    "    \n",
    "    Args:\n",
    "        x(np.ndarray): Аргумент 1\n",
    "        y(np.ndarray): Аргумент 2\n",
    "        \n",
    "    Returns:\n",
    "        np.float64: Результат функции\n",
    "    '''\n",
    "    return np.sin(x + y)+np.square(x - y)-1.5*x+2.5*y+1;\n",
    "\n",
    "#градиент 1\n",
    "def McCormick_Grad(x: np.ndarray, y: np.ndarray) -> np.float64:\n",
    "    return np.array([np.cos(x+y)+2*(x-y)-1.5, np.cos(x+y)-2*(x-y)+2.5]);\n",
    "\n",
    "McCormick(2.5, 3.4), McCormick_Grad(2.5, 3.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
